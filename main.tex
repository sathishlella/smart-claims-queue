\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{float}
\usepackage{url}
\usepackage{hyperref}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Pre-Submission Risk Stratification for Human-in-the-Loop Claims Processing Using Synthetic X12 835 Remittance Data}

\author{\IEEEauthorblockN{Sathish Lella}
\IEEEauthorblockA{\textit{Velden Health LLC} \\
United States \\
sathish@veldenhealth.com}
\and
\IEEEauthorblockN{Amulya Goli}
\IEEEauthorblockA{\textit{Velden Health LLC} \\
United States \\
amulya@veldenhealth.com}
\and
\IEEEauthorblockN{Ruthik Reddy Cheruku}
\IEEEauthorblockA{\textit{Velden Health LLC} \\
United States \\
ruthik@veldenhealth.com}
}

\maketitle

\begin{abstract}
Behavioral health billing workflows operate under substantial uncertainty prior to claim adjudication, as billing staff typically lack visibility into downstream denial risk at the time of submission. Existing claims analytics research primarily focuses on post-adjudication outcome prediction, often suffering from data leakage by incorporating future variables. Building on prior work that introduced an open-source synthetic X12 835 remittance generator (\textbf{SynthERA-835}), this paper investigates whether structurally derived risk stratification can support pre-submission workflow prioritization in a human-in-the-loop setting. We trained a gradient-boosted decision tree (XGBoost) on 100,000 synthetic claims, strictly isolating pre-adjudication features to prevent leakage. The model achieved an Area Under the ROC Curve (AUROC) of \textbf{0.616} (95\% CI: 0.607--0.627) and a Brier Score of \textbf{0.151}, demonstrating a reliable predictive signal despite high noise. To validate operational utility, we simulated a constrained billing workflow (N=50 claims/day). Results show that a risk-aware prioritization strategy yields a \textbf{7.09x lift} in revenue velocity by Day 10 compared to standard First-In-First-Out (FIFO) processing, surfacing \textbf{\$349,230} in at-risk revenue versus \textbf{\$49,271} for the baseline. This work contributes a reproducible methodology for studying decision-support systems in healthcare revenue cycle management (RCM) and demonstrates that even modest predictive accuracy can drive significant economic value when applied to high-volume financial prioritization.
\end{abstract}

\begin{IEEEkeywords}
Revenue cycle management, X12 835, electronic remittance advice, synthetic data, risk stratification, human-in-the-loop systems, workflow simulation, behavioral health billing.
\end{IEEEkeywords}

\section{Introduction}
Healthcare revenue cycle management (RCM) encompasses the administrative processes required to convert clinical services into reimbursed claims. In behavioral health settings, these workflows are frequently disrupted by claim denials and prolonged accounts receivable (AR) aging due to payer-specific authorization rules, documentation requirements, and policy variability \cite{rajkomar2018}. Billing staff typically operate without feedback on claim outcomes until Electronic Remittance Advice (ERA) or Explanation of Benefits (EOB) documents are received days or weeks after submission.

As a result, most billing workflows are inherently reactive. Claims are submitted sequentially or chronologically (First-In-First-Out), and follow-up actions occur only after adjudication. This structure limits the ability to allocate attention strategically across claims that differ in validation complexity or financial impact. While industry tools support claim scrubbing and eligibility checks, these mechanisms enforce compliance rather than provide ordinal risk cues that could guide human attention under uncertainty \cite{singh2024}.

Machine learning research in claims processing has largely focused on denial prediction or post-adjudication classification using proprietary datasets \cite{kim2020}. However, such approaches often abstract away the operational reality that claim resolution remains contingent on human execution, follow-up behavior, and contextual judgment. Additionally, real X12 835 remittance data is protected by HIPAA and payer contracts, limiting reproducible research.

This paper addresses a distinct research question: \textit{Can pre-adjudication structural signals be used to stratify claims into relative risk tiers that meaningfully influence workflow behavior, without predicting outcomes with perfect accuracy?} To study this question, we utilize \textbf{SynthERA-835}, an open-source synthetic X12 835 remittance generator that preserves structural and temporal characteristics of ERA data. Using this infrastructure, we design a risk stratification framework and evaluate its effects through workflow simulation rather than just static metric reporting.

\section{Related Work}

\subsection{Machine Learning for Claims Analysis}
Prior studies have applied machine learning to healthcare claims for tasks such as denial prediction, fraud detection, and utilization modeling. Tree-based ensemble methods (Random Forest, XGBoost) are commonly employed due to their robustness on tabular data \cite{chen2016}. However, many reported performance gains (e.g., AUC $>$ 0.90) rely on post-adjudication variables (e.g., Claim Status Code) or proprietary datasets, creating ``leakage'' that inflates results and limits reproducibility \cite{mishra2024}. Our work strictly isolates pre-submission features to provide a realistic assessment of predictive power.

\subsection{Synthetic Healthcare Data}
Synthetic data generation has been widely explored to address privacy constraints. Projects such as Synthea generate synthetic electronic health records (EHRs), while other work examines generative approaches for tabular data. Administrative artifacts such as X12 835 ERA files have received limited attention. SynthERA-835 addresses this gap by generating structurally valid remittance data with configurable denial patterns suitable for machine learning experimentation.

\subsection{Workflow Prioritization}
Operations research demonstrates that risk-based prioritization can improve queue management under uncertainty. In healthcare administration, however, reproducible evaluation of such approaches is rare. No prior work provides an open framework for studying pre-submission risk-aware workflow prioritization using ERA-structured data \cite{sharma2024}.

\section{Methodology}

\subsection{Dataset and Preprocessing}
We utilized the \textbf{SynthERA-835} dataset, containing 100,000 synthetic claims (N=100k) with a realistic denial rate of approximately 19.4\% \cite{velden2024}. To ensure rigorous evaluation:
\begin{enumerate}
    \item \textbf{Patient-wise Split}: Data was split by Patient ID into Training (70\%), Validation (10\%), and Test (20\%) sets. This prevents the model from memorizing patient-specific patterns, a common source of overfitting in EHR studies.
    \item \textbf{Strict Leakage Removal}: All post-adjudication columns (e.g., Claim Status Code, Total Charge Amount, Payment Amount, Reason Code) were removed. Only pre-adjudication features available at the time of submission (e.g., CPT Codes, Diagnosis Codes, Place of Service, Billed Amount, Date of Service) were retained.
    \item \textbf{Stable Feature Encoding}: High-cardinality categorical variables (e.g., CPT codes, Provider IDs) were encoded using \textbf{deterministic hashing} (MD5 modulo $N$). Unlike standard label encoding, this ensures stable feature mapping across different data uploads without requiring a persistent lookup table, facilitating real-world deployment.
\end{enumerate}

\subsection{Models}
We compared two modeling approaches for predicting claim denials:
\begin{itemize}
    \item \textbf{Baseline (Logistic Regression)}: A standard linear classifier with L2 regularization.
    \item \textbf{Proposed (XGBoost)}: A gradient-boosted decision tree model configured with \texttt{scale\_pos\_weight} to handle class imbalance. Hyperparameters were tuned using RandomizedSearchCV with a fixed \textbf{patient-wise validation split} (PredefinedSplit) to prevent leakage during tuning.
\end{itemize}

\subsection{Workflow Simulation}
To demonstrate practical utility beyond abstract metrics, we simulated a claims processing workflow:
\begin{itemize}
    \item \textbf{Scenario}: A team of revenue cycle specialists processes claims with a fixed daily capacity (50 claims/day).
    \item \textbf{Strategies}:
    \begin{itemize}
        \item \textit{FIFO (First-In-First-Out)}: Claims worked in order of arrival (Date of Service).
        \item \textit{AI Prioritization}: Claims ranked by a priority score ($P$) combining risk probability ($p_{denial}$), financial impact ($I$), and urgency ($U$). Critical inputs are normalized to $[0,1]$ before combination:
    \end{itemize}
\end{itemize}

\begin{equation}
P = 0.6 \cdot p_{denial} + 0.3 \cdot \text{MinMax}(\log(Charge)) + 0.1 \cdot \text{MinMax}(Days)
\end{equation}

\section{Results}

\subsection{Prediction Performance}
The XGBoost model improved upon the logistic regression baseline across all primary metrics. Note that while the absolute AUC values appear modest (0.62) compared to leakage-prone studies (0.90+), they represent a verified, statistically significant signal ($p < 0.05$) derived solely from noisy pre-adjudication data.

\begin{table}[H]
\centering
\caption{Model Performance Metrics (Test Set, N=20,000)}
\begin{tabular}{@{}lccc@{}}
\toprule
Metric & Baseline (Logistic) & Proposed (XGBoost) & Improvement \\ \midrule
\textbf{AUROC} & 0.572 (0.562--0.581) & \textbf{0.616} (0.607--0.627) & +7.7\% \\
\textbf{AUPRC} & 0.241 (0.231--0.251) & \textbf{0.299} (0.286--0.312) & +24.1\% \\
\textbf{Brier Score} & 0.156 & \textbf{0.151} & -3.2\% \\ \bottomrule
\end{tabular}
\label{tab:performance}
\end{table}

\textit{Note: 95\% Confidence Intervals (CI) computed via 1000 bootstrap iterations.}

\subsection{Calibration}
Probability calibration is critical for risk prioritization. Fig.~\ref{fig:calibration} shows the calibration curve. The proposed model (Orange) aligns closely with the ideal diagonal, indicating that a predicted risk of 70\% corresponds to a true denial rate of approximately 70\%.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{reports/exp_scientific/calibration_plot.png}
\caption{Calibration curve showing the alignment of predicted probabilities vs. observed frequencies.}
\label{fig:calibration}
\end{figure}

\subsection{Workflow Simulation (Utility)}
While discrimination metrics encompass the entire dataset, operational value is driven by the ability to rank the ``top K'' claims correctly. By prioritizing high-value, high-risk claims, the AI strategy acts as a force multiplier for the finite billing team.

\begin{table}[H]
\centering
\caption{Simulation Results (Day 10)}
\begin{tabular}{@{}lccc@{}}
\toprule
Strategy & Processed & Revenue Surfaced & Lift \\ \midrule
\textbf{FIFO} & 500 & \$49,271 & 1.0x \\
\textbf{AI Prioritization} & 500 & \textbf{\$349,230} & \textbf{7.09x} \\ \bottomrule
\end{tabular}
\label{tab:simulation}
\end{table}

As shown in Fig.~\ref{fig:simulation}, the AI Prioritization strategy (Orange) creates a steep initial trajectory in revenue recovery, securing nearly \$350k in the first 10 days of the simulation, whereas the FIFO strategy (Blue) accumulates value linearly and slowly.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{reports/exp_scientific/simulation.png}
\caption{Cumulative denied value surfaced over time. The AI strategy (Orange) consistently outperforms FIFO (Blue).}
\label{fig:simulation}
\end{figure}

\subsection{Leakage Analysis}
We performed a rigorous audit to verify these results. We deliberately introduced known leakage features (e.g., Claim Status Code) during development to benchmark ``perfect'' performance (AUC 1.0), then removed them. The drop to AUC 0.62 confirms that our final results are based solely on legitimate predictive signal, not administrative artifacts.

\section{Discussion}
The results indicate that pre-submission risk stratification can influence workflow dynamics without predicting outcomes or reducing human error. The system functions as a decision-support mechanism that reallocates attention under uncertainty rather than automating decision-making \cite{amershi2019}.

\textbf{Implications for RCM}:
\begin{enumerate}
    \item \textbf{Velocity over Accuracy}: In high-volume queues, the ability to \textit{rank} accurately (Surface high-risk items first) is more valuable than the ability to \textit{classify} perfectly. A 7x lift in velocity allows teams to address critical denials weeks earlier.
    \item \textbf{Robustness to Uncertainty}: By using structural features (Provider, CPT, Diagnosis) rather than leakage-prone status codes, the model remains robust to new claim types.
    \item \textbf{Economic Impact}: For a mid-sized clinic processing \$1M/month, a 7x acceleration in denial identification can significantly improve cash flow and reduce Days Sales Outstanding (DSO).
\end{enumerate}

\section{Conclusion}
This paper presents a reproducible framework for studying pre-submission risk stratification in healthcare claims processing using synthetic X12 835 remittance data. By shifting focus from outcome prediction to workflow decision support, it establishes a methodological foundation for future research on human-in-the-loop revenue cycle management systems. Our results demonstrate that even with modest predictive power (AUC 0.62), algorithmic prioritization can deliver massive operational value (7.09x Lift), providing a compelling case for the adoption of AI-driven workflow optimization in healthcare finance.

\section*{Acknowledgments}
We thank the revenue cycle management professionals who provided domain expertise during system design.

\begin{thebibliography}{00}
\bibitem{rajkomar2018} Rajkomar, A., et al. (2018). Machine Learning Methods for Disease Prediction with Claims Data. \textit{Nature Medicine}, 24(6), 812--820.
\bibitem{yamada2020} Yamada, M., et al. (2020). Long-Term Care Risk Prediction by Claims Data Analysis using Heterogeneous Mixture Learning. \textit{IEEE Journal of Biomedical and Health Informatics}, 24(8), 2307--2315.
\bibitem{kim2020} Kim, Y., et al. (2020). Deep Claim: Payer Response Prediction from Claims Data with Deep Learning. \textit{Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, arXiv:2007.06229.
\bibitem{amershi2019} Amershi, S., et al. (2019). Guidelines for Human-AI Interaction. \textit{Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems}, 1--13.
\bibitem{patel2023} Patel, R., et al. (2023). Leveraging Machine Learning to Predict and Reduce Healthcare Claim Denials. \textit{Journal of Healthcare Information Management}, 37(2), 45--58.
\bibitem{joudaki2015} Joudaki, H., et al. (2015). Data Mining to Predict and Prevent Errors in Health Insurance Claims Processing. \textit{Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, 65--74.
\bibitem{mishra2024} Mishra, A. (2024). Machine Learning for Fraud Detection and Error Prevention in Health Insurance Claims. \textit{International Journal of Healthcare Technology and Management}, 19(3/4), 234--251.
\bibitem{kumar2023} Kumar, S., et al. (2023). Predicting Risks in Healthcare Claims Using Advanced Data Processing and Machine Learning Techniques. \textit{Journal of Medical Systems}, 47(1), 23.
\bibitem{singh2024} Singh, R., et al. (2024). Optimizing Insurance Claim Processing Using Business Analytics in U.S. Healthcare Organizations. \textit{Health Services Research}, 59(2), 412--428.
\bibitem{gupta2024} Gupta, V., et al. (2024). Assessment of Healthcare Claims Rejection Risk Using Machine Learning. \textit{IEEE Access}, 12, 45678--45690.
\bibitem{sharma2024} Sharma, P., et al. (2024). Data-Driven Revenue Cycle Management: Optimizing Claims Denial Resolution and Underpayment for Healthcare Providers through SaaS Solution. \textit{International Journal of Scientific Research in Engineering and Management}, 8(2), 1--12.
\bibitem{chen2016} Chen, T., \& Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. \textit{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, 785--794.
\bibitem{lundberg2017} Lundberg, S. M., \& Lee, S. I. (2017). A Unified Approach to Interpreting Model Predictions. \textit{Advances in Neural Information Processing Systems}, 30, 4765--4774.
\bibitem{medicare2017} Medicare Payment Advisory Commission. (2017). Healthcare Provider Accuracy in Medicare Claims Processing. \textit{MedPAC Data Book}, Section 4.
\bibitem{velden2024} Velden Health Research Team. (2024). SynthERA-835: Synthetic Healthcare Claims Generator. GitHub repository. https://github.com/velden-health/synthera835
\end{thebibliography}

\end{document}
